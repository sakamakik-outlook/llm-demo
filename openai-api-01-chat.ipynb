{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sakamakik-outlook/llm-demo/blob/master/openai-api-01-chat.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (0.27.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (from openai) (2.29.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sakam\\anaconda3\\envs\\pytorch01\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"  # <-- replace this with your own key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4\n",
      "gpt-4-0314\n",
      "gpt-3.5-turbo-0613\n",
      "gpt-4-0613\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-16k-0613\n",
      "ft:gpt-3.5-turbo-0613:personal::7zx2vYe6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "models = openai.Model.list()\n",
    "\n",
    "\n",
    "# Print only id line by line, only print gpt models\n",
    "# gpt_models = [model for model in models[\"data\"] if \"gpt\" in model[\"id\"]]\n",
    "# ids = [model[\"id\"] for model in gpt_models]\n",
    "# for id in ids:\n",
    "#     print(id)\n",
    "\n",
    "# Create a unit test to verify the following:\n",
    "\n",
    "# - Ensure that 'gpt-4' is included in the list of IDs.\n",
    "# - Confirm that 'gpt-5' is not present in the list.\n",
    "# Please note:\n",
    "# - Retrieve the API key from an environment variable.\n",
    "# - Execute the test within a Jupyter Notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.404s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import openai\n",
    "import os\n",
    "\n",
    "class TestModelList(unittest.TestCase):\n",
    "    def test_model_list(self):\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        models = openai.Model.list()\n",
    "        ids = [model[\"id\"] for model in models[\"data\"]]\n",
    "        ids.sort()\n",
    "        self.assertIn(\"gpt-4\", ids)\n",
    "        self.assertNotIn(\"gpt-5\", ids)\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestModelList)\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details about models, https://platform.openai.com/docs/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FYI: An example of LLM application for code generation. \n",
    "\n",
    "  Github co-pilot can write and run a unit test. \n",
    "\n",
    "  https://github.com/features/preview/copilot-x\n",
    "\n",
    "\n",
    "![Alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def generate_chat_response(messages):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k-0613\",\n",
    "        messages=messages, \n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the United States of America is Washington, D.C.\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "{\"role\": \"user\", \"content\": \"what is the capital of USA? \"},\n",
    "]\n",
    "generate_chat_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, come on! You don't know the capital of the USA? It's Washington, D.C.\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "{\"role\": \"system\", \"content\": \"You are a sarcastic assistant.\"},\n",
    "{\"role\": \"user\", \"content\": \"what is the capital of USA?\"},\n",
    "]\n",
    "generate_chat_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT AVG(total_order_value) AS average_total_order_value\n",
      "FROM (\n",
      "    SELECT o.OrderID, SUM(p.UnitPrice * od.Quantity) AS total_order_value\n",
      "    FROM Orders o\n",
      "    INNER JOIN OrderDetails od ON o.OrderID = od.OrderID\n",
      "    INNER JOIN Products p ON od.ProductID = p.ProductID\n",
      "    WHERE o.OrderDate = '2023-04-01'\n",
      "    GROUP BY o.OrderID\n",
      ") AS subquery;\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \n",
    "     \"\"\"\n",
    "        Given the following SQL tables, your job is to write queries given a user’s request.\n",
    "\n",
    "        CREATE TABLE Orders (\n",
    "        OrderID int,\n",
    "        CustomerID int,\n",
    "        OrderDate datetime,\n",
    "        OrderTime varchar(8),\n",
    "        PRIMARY KEY (OrderID)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE OrderDetails (\n",
    "        OrderDetailID int,\n",
    "        OrderID int,\n",
    "        ProductID int,\n",
    "        Quantity int,\n",
    "        PRIMARY KEY (OrderDetailID)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE Products (\n",
    "        ProductID int,\n",
    "        ProductName varchar(50),\n",
    "        Category varchar(50),\n",
    "        UnitPrice decimal(10, 2),\n",
    "        Stock int,\n",
    "        PRIMARY KEY (ProductID)\n",
    "        );\n",
    "\n",
    "     \"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a SQL query which computes the average total order value for all orders on 2023-04-01. \"}\n",
    "]\n",
    "\n",
    "generate_chat_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The code is a COBOL program that generates a test log report.\n",
      "- It reads input from a file called TLOG and writes output to a file called RPTFILE.\n",
      "- The program loops through the input file, writing each record to the output file until the end of the input file is reached.\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \n",
    "     \"\"\"Given the following COBOL code, your job is to summarize the code in plain English.\n",
    "\n",
    "\n",
    "       **************************************************************************\n",
    "      * CATEGORY.: HPMS COBOL PROGRAMS\n",
    "      * GROUP....: COBOL\n",
    "      * AUTHOR...: LANCE HAYNIE <LANCE@HAYNIEMAIL.COM>\n",
    "      * DATE.....: 2017-10-02\n",
    "      * PURPOSE..: TEST LOG REPORT\n",
    "      **************************************************************************\n",
    "      * MODIFICATIONS\n",
    "      * 2017-10-02 - LHAYNIE - INITIAL VERSION\n",
    "      **************************************************************************\n",
    "       IDENTIFICATION DIVISION.\n",
    "       PROGRAM-ID.  TLOGRPT.\n",
    "      **************************************************************************\n",
    "       ENVIRONMENT DIVISION.\n",
    "       INPUT-OUTPUT SECTION.\n",
    "       FILE-CONTROL.\n",
    "           SELECT INFILE ASSIGN TO TLOG.\n",
    "           SELECT OUTFILE ASSIGN TO RPTFILE.\n",
    "       DATA DIVISION.\n",
    "       FILE SECTION.\n",
    "       FD INFILE\n",
    "           RECORDING MODE F.\n",
    "       COPY TLOG.\n",
    "       FD OUTFILE\n",
    "           RECORDING MODE V.\n",
    "       01  OUTFILE-RECORD              PIC X(200).\n",
    "       WORKING-STORAGE SECTION.\n",
    "       01  WS-CURRENT-DATE.\n",
    "           05  WS-YEAR                 PIC 9(4).\n",
    "           05  WS-MONTH                PIC 9(2).\n",
    "           05  WS-DAY                  PIC 9(2).\n",
    "           05  WS-HOURS                PIC 9(2).\n",
    "           05  WS-MINUTES              PIC 9(2).\n",
    "           05  WS-SECONDS              PIC 9(2).\n",
    "           05  WS-HUND-SECOND          PIC 9(2).\n",
    "           05  WS-GMT                  PIC X(5).\n",
    "       01  OUT-RECORD.\n",
    "           05  ID-OUT                  PIC X(6).\n",
    "           05  FILLER                  PIC X(2)\n",
    "               VALUE  SPACES.\n",
    "           05  DATE-OUT.\n",
    "               10  YEAR-OUT            PIC X(4).\n",
    "               10  FILLER              PIC X\n",
    "                   VALUE '-'.\n",
    "               10  MONTH-OUT           PIC X(2).\n",
    "               10  FILLER              PIC X\n",
    "                   VALUE '-'.\n",
    "               10  DAY-OUT             PIC X(2).\n",
    "           05  FILLER                  PIC X(2)\n",
    "               VALUE  SPACES.\n",
    "           05  CATEGORY-OUT            PIC X(28).\n",
    "           05  FILLER                  PIC X(2)\n",
    "               VALUE  SPACES.\n",
    "           05  GROUP-OUT               PIC X(28).\n",
    "           05  FILLER                  PIC X(2)\n",
    "               VALUE SPACES.\n",
    "           05  AUTHOR-OUT              PIC X(28).\n",
    "           05  FILLER                  PIC X(2)\n",
    "               VALUE SPACES.\n",
    "           05  SUBJECT-OUT             PIC X(66).\n",
    "       01  DATE-LINE.\n",
    "           05  FILLER                  PIC X(12)\n",
    "               VALUE 'REPORT DATE:'.\n",
    "           05  FILLER                  PIC X(1)\n",
    "               VALUE SPACES.\n",
    "           05  DT-YEAR                 PIC 9(4).\n",
    "           05  FILLER                  PIC X\n",
    "               VALUE '/'.\n",
    "           05  DT-MONTH                PIC 9(2).\n",
    "           05  FILLER                  PIC X\n",
    "               VALUE '/'.\n",
    "           05  DT-DAY                  PIC 9(2).\n",
    "       01  HEADER-1.\n",
    "           05  FILLER                  PIC X(100)\n",
    "               VALUE  'HAYNIE RESEARCH & DEVELOPMENT'.\n",
    "       01  HEADER-2.\n",
    "           05  FILLER                  PIC X(100)\n",
    "               VALUE  'TEST LOG REPORT'.\n",
    "       01  HEADER-3.\n",
    "           05  FILLER                  PIC X(8)\n",
    "               VALUE  'ID'.\n",
    "           05  FILLER                  PIC X(12)\n",
    "               VALUE  'DATE'.\n",
    "           05  FILLER                  PIC X(30)\n",
    "               VALUE  'CATEGORY'.\n",
    "           05  FILLER                  PIC X(30)\n",
    "               VALUE  'GROUP'.\n",
    "           05  FILLER                  PIC X(30)\n",
    "               VALUE  'AUTHOR'.\n",
    "           05  FILLER                  PIC X(66)\n",
    "               VALUE  'SUBJECT'.\n",
    "       01  HEADER-4.\n",
    "           05  FILLER                  PIC X(6)\n",
    "               VALUE  '------'.\n",
    "           05  FILLER                  PIC X(2)\n",
    "               VALUE SPACES.\n",
    "           05  FILLER                  PIC X(10)\n",
    "               VALUE  '----------'.\n",
    "           05  FILLER                  PIC X(2)\n",
    "               VALUE SPACES.\n",
    "           05  FILLER                  PIC X(10)\n",
    "               VALUE '----------'.\n",
    "           05  FILLER                  PIC X(10)\n",
    "               VALUE '----------'.\n",
    "           05  FILLER                  PIC X(8)\n",
    "               VALUE '--------'.\n",
    "           05  FILLER                  PIC X(2)\n",
    "               VALUE SPACES.\n",
    "           05  FILLER                  PIC X(10)\n",
    "               VALUE '----------'.\n",
    "           05  FILLER                  PIC X(10)\n",
    "               VALUE '----------'.\n",
    "           05  FILLER                  PIC X(8)\n",
    "               VALUE '--------'.\n",
    "           05  FILLER                  PIC X(2)\n",
    "               VALUE SPACES.\n",
    "           05  FILLER                  PIC X(10)\n",
    "               VALUE '----------'.\n",
    "           05  FILLER                  PIC X(10)\n",
    "               VALUE '----------'.\n",
    "           05  FILLER                  PIC X(8)\n",
    "               VALUE '--------'.\n",
    "           05  FILLER                  PIC X(2)\n",
    "               VALUE SPACES.\n",
    "           05  FILLER                  PIC X(10)\n",
    "               VALUE '----------'.\n",
    "           05  FILLER                  PIC X(10)\n",
    "               VALUE '----------'.\n",
    "           05  FILLER                  PIC X(10)\n",
    "               VALUE '----------'.\n",
    "           05  FILLER                  PIC X(10)\n",
    "               VALUE '----------'.\n",
    "           05  FILLER                  PIC X(10)\n",
    "               VALUE '----------'.\n",
    "           05  FILLER                  PIC X(10)\n",
    "               VALUE '----------'.\n",
    "           05  FILLER                  PIC X(6)\n",
    "               VALUE '------'.\n",
    "\n",
    "       01  SWITCHES.\n",
    "           05  TLOG-EOF-SWITCH         PIC X(1) VALUE 'N'.\n",
    "       PROCEDURE DIVISION.\n",
    "       MAIN-PROGRAM.\n",
    "           MOVE FUNCTION CURRENT-DATE TO WS-CURRENT-DATE.\n",
    "           MOVE WS-YEAR TO DT-YEAR.\n",
    "           MOVE WS-MONTH TO DT-MONTH.\n",
    "           MOVE WS-DAY TO DT-DAY.\n",
    "           OPEN INPUT INFILE\n",
    "                OUTPUT OUTFILE.\n",
    "           READ INFILE\n",
    "               AT END\n",
    "                   MOVE 'Y' TO TLOG-EOF-SWITCH\n",
    "           END-READ.\n",
    "           PERFORM PRINT-TITLE\n",
    "           PERFORM DATA-LOOP\n",
    "               UNTIL TLOG-EOF-SWITCH = 'Y'\n",
    "           CLOSE INFILE\n",
    "                 OUTFILE.\n",
    "           STOP RUN.\n",
    "       PRINT-TITLE.\n",
    "           MOVE HEADER-1 TO OUTFILE-RECORD.\n",
    "           WRITE OUTFILE-RECORD.\n",
    "           MOVE HEADER-2 TO OUTFILE-RECORD.\n",
    "           WRITE OUTFILE-RECORD.\n",
    "           MOVE DATE-LINE TO OUTFILE-RECORD.\n",
    "           WRITE OUTFILE-RECORD.\n",
    "           MOVE SPACES TO OUTFILE-RECORD.\n",
    "           WRITE OUTFILE-RECORD.\n",
    "           MOVE HEADER-3 TO OUTFILE-RECORD.\n",
    "           WRITE OUTFILE-RECORD.\n",
    "           MOVE HEADER-4 TO OUTFILE-RECORD.\n",
    "           WRITE OUTFILE-RECORD.\n",
    "       DATA-LOOP.\n",
    "           MOVE TEST-RECORD-ID TO ID-OUT.\n",
    "           MOVE TEST-YEAR TO YEAR-OUT.\n",
    "           MOVE TEST-MONTH TO MONTH-OUT.\n",
    "           MOVE TEST-DAY TO DAY-OUT.\n",
    "           MOVE TEST-CATEGORY TO CATEGORY-OUT.\n",
    "           MOVE TEST-GROUP TO GROUP-OUT.\n",
    "           MOVE TEST-AUTHOR TO AUTHOR-OUT.\n",
    "           MOVE TEST-SUBJECT TO SUBJECT-OUT.\n",
    "           MOVE OUT-RECORD TO OUTFILE-RECORD.\n",
    "           WRITE OUTFILE-RECORD.\n",
    "           READ INFILE\n",
    "               AT END\n",
    "                   MOVE 'Y' TO TLOG-EOF-SWITCH\n",
    "           END-READ.\n",
    "     \"\"\"},\n",
    "    {\"role\": \"user\", \"content\":  \"Summarize the COBOL code in three bullet points.\"}\n",
    "]\n",
    "\n",
    "generate_chat_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ChatGPT is an AI-powered chatbot developed by OpenAI that uses GPT-3.5 Turbo and GPT-4 algorithms.\n",
      "- It can answer questions, write copy, hold conversations, and perform various tasks based on natural language prompts.\n",
      "- ChatGPT works by predicting the best response to a prompt using deep learning neural networks trained on vast amounts of unlabeled data from the internet.\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \n",
    "     \"\"\" Given the following explanations of GPT-3, your job is to write a summary of the explanations in plain English.\n",
    "\n",
    "ChatGPT has been a household name for less than a year, but the algorithms working in the background of the popular AI tool have actually been powering a whole range of apps and services since 2020. So to understand how ChatGPT works, we need to start by talking about the underlying language engine that powers it.\n",
    "The GPT in ChatGPT is mostly two related algorithms: GPT-3.5 Turbo and GPT-4, though the latter is only available in ChatGPT for ChatGPT Plus subscribers. The GPT bit stands for Generative Pre-trained Transformer, and the number is just the version of the algorithm. The GPT models were developed by OpenAI (the company behind ChatGPT and the image generator DALL·E 2), but they power everything from Bing's AI features to writing tools like Jasper and Copy.ai. In fact, most of the AI text generators available at the moment use GPT-3, GPT-3.5, and GPT-4—though they tend to keep quiet when they use each one.\n",
    "See OpenAI’s CEO at ZapConnect\n",
    "Join us for a fireside chat with Sam Altman at our free virtual user conference. Learn how to use AI and automation to sustainably scale your business.\n",
    "Save your spot\n",
    "ChatGPT brought GPT into the limelight because it made the process of interacting with an AI text generator simple and—most importantly—free to everyone. Plus, it's a chatbot, and people have loved a good chatbot since SmarterChild.\n",
    "While GPT-3.5 and GPT-4 are the most popular large language models (LLMs) right now, over the next few years, there's likely to be a lot more competition. Google, for example, has Bard—its AI chatbot—which is powered by its own language engine, Pathways Language Model (PaLM 2). Meta, Facebook's parent company, released Llama 2, its latest LLM. And then there are other options aimed at large companies, like Writer's Palmyra LLMs and Anthropic's Claude. Still, at least for now, OpenAI's offering is the de facto industry standard. It's just the easiest tool for people to get their hands on.  \n",
    "So the answer to \"how does ChatGPT work?\" is basically: GPT-3.5 and GPT-4. But let's dig a little deeper.\n",
    "ChatGPT has been a household name for less than a year, but the algorithms working in the background of the popular AI tool have actually been powering a whole range of apps and services since 2020. So to understand how ChatGPT works, we need to start by talking about the underlying language engine that powers it.\n",
    "The GPT in ChatGPT is mostly two related algorithms: GPT-3.5 Turbo and GPT-4, though the latter is only available in ChatGPT for ChatGPT Plus subscribers. The GPT bit stands for Generative Pre-trained Transformer, and the number is just the version of the algorithm. The GPT models were developed by OpenAI (the company behind ChatGPT and the image generator DALL·E 2), but they power everything from Bing's AI features to writing tools like Jasper and Copy.ai. In fact, most of the AI text generators available at the moment use GPT-3, GPT-3.5, and GPT-4—though they tend to keep quiet when they use each one.\n",
    "See OpenAI’s CEO at ZapConnect\n",
    "Join us for a fireside chat with Sam Altman at our free virtual user conference. Learn how to use AI and automation to sustainably scale your business.\n",
    "Save your spot\n",
    "ChatGPT brought GPT into the limelight because it made the process of interacting with an AI text generator simple and—most importantly—free to everyone. Plus, it's a chatbot, and people have loved a good chatbot since SmarterChild.\n",
    "While GPT-3.5 and GPT-4 are the most popular large language models (LLMs) right now, over the next few years, there's likely to be a lot more competition. Google, for example, has Bard—its AI chatbot—which is powered by its own language engine, Pathways Language Model (PaLM 2). Meta, Facebook's parent company, released Llama 2, its latest LLM. And then there are other options aimed at large companies, like Writer's Palmyra LLMs and Anthropic's Claude. Still, at least for now, OpenAI's offering is the de facto industry standard. It's just the easiest tool for people to get their hands on.  \n",
    "So the answer to \"how does ChatGPT work?\" is basically: GPT-3.5 and GPT-4. But let's dig a little deeper.\n",
    "With Zapier, you can connect ChatGPT to thousands of other apps to bring AI into all your business-critical workflows.\n",
    "What is ChatGPT?\n",
    "ChatGPT is an app built by OpenAI. Using the GPT language models, it can answer your questions, write copy, draft emails, hold a conversation, explain code in different programming languages, translate natural language to code, and more—or at least try to—all based on the natural language prompts you feed it. It's a chatbot, but a really, really good one.\n",
    "Examples, capabilities, and limitations of ChatGPT\n",
    "Image from ChatGPT\n",
    "While it's cool to play around with if, say, you want to write a Shakespearean sonnet about your pet or get a few ideas for subject lines for some marketing emails, it's also good for OpenAI. It's a way to get a lot of data from real users and serves as a fancy demo for the power of GPT, which could otherwise feel a little fuzzy unless you were deep into machine learning. (That data collection got ChatGPT blocked in Italy in early 2023, though the Italian regulators' concerns have now been resolved.)\n",
    "Right now, ChatGPT offers two GPT models. The default, GPT-3.5, is less powerful but available to everyone for free. The more advanced GPT-4 is limited to ChatGPT Plus subscribers, and even they only get a limited number of questions every day. (It's 25 messages every three hours at present, but that could change.)\n",
    "One of ChatGPT's big features is that it can remember the conversation you're having with it. This means it can glean context from whatever you've asked it previously and then use that to inform its conversation with you. You're also able to ask for reworks and corrections, and it will refer back to whatever you'd been discussing before. It makes interacting with the AI feel like a genuine back-and-forth. \n",
    "If you want to really get a feel for it, go and spend five minutes playing with ChatGPT now (it's free!), and then come back to read about how it works. \n",
    "How does ChatGPT work?\n",
    "This humongous dataset was used to form a deep learning neural network [...] modeled after the human brain—which allowed ChatGPT to learn patterns and relationships in the text data [...] predicting what text should come next in any given sentence. \n",
    "ChatGPT works by attempting to understand your prompt and then spitting out strings of words that it predicts will best answer your question, based on the data it was trained on. While that might sound relatively simple, it belies the complexity of what's going on under the hood. \n",
    "Supervised vs. unsupervised learning\n",
    "Let's actually talk about that training. The P in GPT stands for \"pre-trained,\" and it's a super important part of why GPT is able to do what it can do. \n",
    "Before GPT, the best performing AI models used \"supervised learning\" to develop their underlying algorithms. They were trained with manually-labeled data, like a database with photos of different animals paired with a text description of each animal written by humans. These kinds of training data, while effective in some circumstances, are incredibly expensive to produce. Even now, there just isn't that much data suitably labeled and categorized to be used to train LLMs.\n",
    "Instead, GPT employed generative pre-training, where it was given a few ground rules and then fed vast amounts of unlabeled data—near enough the entire open internet. It was then left \"unsupervised\" to crunch through all this data and develop its own understanding of the rules and relationships that govern text. \n",
    "Of course, you don't really know what you're going to get when you use unsupervised learning, so GPT is also \"fine-tuned\" to make its behavior more predictable and appropriate. There are a few ways this is done (which I'll get to), but it often uses forms of supervised learning\n",
    "     \"\"\"},\n",
    "    {\"role\": \"user\", \"content\":  \"Summarize text in three bullet points.\"}\n",
    "]\n",
    "\n",
    "generate_chat_response(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Root cause: A misconfiguration in the code deployment for the Azure Container Apps service caused a loop of restarts, overwhelming the telemetry management control plane.\n",
      "- Start time: 23:15 UTC on 6 July 2023\n",
      "- End time: 09:00 UTC on 7 July 2023\n",
      "- Duration: Approximately 9 hours and 45 minutes\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \n",
    "     \"\"\" Given the following explanations of Azure outage, your job is to write a summary of the explanations in plain English.\n",
    "\n",
    "        What happened? \n",
    "\n",
    "        Between 23:15 UTC on 6 July 2023 and 09:00 UTC on 7 July 2023, a subset of data for Azure Monitor Log Analytics and Microsoft Sentinel failed to ingest. \n",
    "        Additionally, platform logs gathered via Diagnostic Settings failed to route some data to customer destinations such as Log Analytics, Storage, Event \n",
    "        Hub and Marketplace. These failures were caused by a deployment of a service within Microsoft, with a bug that caused a much higher than expected call\n",
    "        volume that overwhelmed the telemetry management control plane. Customers in all regions experienced impact.\n",
    "\n",
    "        Security Operations Center (SOC) functionality in Sentinel may have been impacted. Queries against impacted tables with date range listed above,\n",
    "        inclusive of the logs data that we failed to ingest, might have returned partial or empty results. This includes analytics (detections), hunting\n",
    "        queries, workbooks with custom queries, and notebooks. In cases where Event or Security Event tables were impacted, incident investigations of a \n",
    "        correlated incident may have showed partial or empty results. \n",
    "\n",
    "        What went wrong and why? \n",
    "\n",
    "        A code deployment for the Azure Container Apps service was started on 3 July 2023 via the normal Safe Deployment Practices (SDP), first rolling \n",
    "        out to Azure canary and staging regions. This version contained a misconfiguration that blocked the service from starting normally. Due to the \n",
    "        misconfiguration, the service bootstrap code threw an exception, and was automatically restarted. This caused the bootstrap service to be stuck\n",
    "        in a loop where it was being restarted every 5 to 10 seconds. Each time the bootstrap service was restarted, it provided configuration information\n",
    "        to the telemetry agents also installed on the service hosts. Each time the configuration information was sent to the telemetry hosts, they\n",
    "        interpreted this as a configuration change, and therefore they also automatically exited their current process and restarted as well. \n",
    "        Three separate instances of the agent telemetry host, per application host, were now also restarting every 5 to 10 seconds.\n",
    "\n",
    "        Upon each startup of the telemetry agent, the agent immediately contacted the telemetry control plane to download the latest version of the\n",
    "        telemetry configuration. Normally this is an action that would take place one time every several days, as this configuration would be cached\n",
    "        on the agent. However, as the deployment of the Container Apps service progressed, several hundred hosts now had their telemetry agents requesting \n",
    "        startup configuration information from the telemetry control plane every 5-10 seconds. The Container Apps team detected the fault in their deployment\n",
    "        on 6 July 2023, stopped the original deployment before it was released to any production regions, and started a new deployment of their service in \n",
    "        the canary and staging regions to correct the misconfiguration.\n",
    "\n",
    "        However, the aggregate rate of requests from the services that received the build with the misconfiguration exhausted capacity on the telemetry\n",
    "        control plane. The telemetry control plane is a global service, used by services running in all public regions of Azure. As capacity on the control \n",
    "        plane was saturated, other services involved in ingestion of telemetry, such as the ingestion front doors and the pipeline services that route data\n",
    "        between services internally, began to fail as their operations against the telemetry control plane were either rejected or timed out. The design of\n",
    "        the telemetry control plane as a single point of failure is a known risk, and investment to eliminate this risk has been underway in Azure Monitor \n",
    "        to design this risk out of the system.\n",
    "\n",
    "        How did we respond?\n",
    "\n",
    "        The impact on the telemetry control plane grew slowly and did not create problems that were detected until 12:30 UTC on 6 July 2023. When the issues were detected, the source of the additional load against the telemetry control plane was not known, but the team suspected additional load had been created against the control plane and took these actions:\n",
    "\n",
    "        6 July 2023 @ 14:53 UTC – Internal incident bridge created.\n",
    "        6 July 2023 @ 15:56 UTC – ~500 instances of garbage collector service were removed, to reduce load on telemetry control plane\n",
    "        6 July 2023 @ 16:09 UTC – First batch of Node Diagnostics servers were removed, to reduce load on telemetry control plane. This process of removing this type of server continued over the next 10 hours.\n",
    "        6 July 2023 @ 20:20 UTC – Source of anomalously high traffic was identified, and the responsible team was paged to assist.\n",
    "        6 July 2023 @ 23:00 UTC – IP address blocks deployed, to prevent anomalous traffic from hitting telemetry control plane.\n",
    "        6 July 2023 @ 23:15 UTC – External customer impact started, as cached data started to expire.\n",
    "        7 July 2023 @ 01:30 UTC – Three additional clusters were added to telemetry control plane to handle additional load, and we began restarting existing clusters to clear backlogged connections.\n",
    "        7 July 2023 @ 02:19 UTC – Initial customer notification was posted to the Azure Status page, to acknowledge the incident was being investigated while we worked to identify which specific subscriptions were impacted.\n",
    "        7 July 2023 @ 02:45 UTC – An additional three clusters were added to telemetry control plane.\n",
    "        7 July 2023 @ 06:15 UTC – Targeted customer notifications sent via Azure Service Health to customers with impacted subscriptions (sent on Tracking ID XMGF-5Z0).\n",
    "        7 July 2023 @ 09:00 UTC – Incident declared mitigated, as call error rate and call latency against control plane APIs stabilized at typical levels.\n",
    "     \"\"\"},\n",
    "     \n",
    "    {\"role\": \"user\", \"content\":  \"List the root cause, the start time, end time, and duration of the incident in bullet points.\"}\n",
    "]\n",
    "\n",
    "generate_chat_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
